# src/config.py

import os

# -------------------------------------------------
# Параметры для Bybit (Unified v5)
# -------------------------------------------------
BYBIT_API_KEY = os.getenv("BYBIT_API_KEY", "")
BYBIT_API_SECRET = os.getenv("BYBIT_API_SECRET", "")

# Пример тикера и настроек
BYBIT_SYMBOL = "BTCUSDT"

# Если вы торгуете фьючерсами USDT-перпетуал, ставьте "linear".
# Для спота — "spot".
BYBIT_CATEGORY = "spot"

# Интервал свечей (строка в минутах):
# Можно оставить "60" (1 час), если основной анализ — часовой ТФ,
# но для мультитаймфрейма (день/4ч/1ч) вы всё равно будете
# загружать их через отдельные вызовы (см. load_multi_timeframe).
BYBIT_INTERVAL = "60"

# Начало и конец периода данных.
# Чем больше период, тем больше исторических данных (и лучше для обучения).
# Здесь пример на ~2+ года.
BYBIT_START_DATE = "2023-01-01"
BYBIT_END_DATE   = "2025-02-20"

# -------------------------------------------------
# Пути к данным
# -------------------------------------------------
RAW_DATA_PATH = "data/raw"
PROCESSED_DATA_PATH = "data/processed"

# -------------------------------------------------
# Параметры для кластеризации (пример)
# -------------------------------------------------
# Если вы используете DBSCAN или похожий алгоритм для кластеризации уровней,
# EPS_PERCENT определяет «радиус» вокруг цен. 0.3–0.5% обычно бывает достаточно,
# но для низковолатильных инструментов можно уменьшать.
EPS_PERCENT = 0.003  # 0.3% от текущей цены
MIN_SAMPLES = 3      # требуем минимум 3 касания для подтверждения уровня

# -------------------------------------------------
# Параметры модели (глубокого обучения)
# -------------------------------------------------
# Допустим, мы подаём только 1 признак (Close), 
# но при желании можно увеличить INPUT_SIZE, если используем Open, High, Low, Volume и т.д.
INPUT_SIZE = 1

# Размер скрытого состояния LSTM/GRU. 64 обычно достаточно для большинства задач
# на последовательности. При большом объёме данных можно увеличить до 128–256.
HIDDEN_SIZE = 64

# Количество слоёв в RNN/LSTM/GRU. 2 — распространённый выбор.
NUM_LAYERS = 2

# Выход (например, 1 логит или 1 вероятность).
OUTPUT_SIZE = 1

# Скорость обучения. 0.001 — часто бывает «быстро» для RNN. 
# 0.0005 даёт более плавное обучение и часто лучше сходится, 
# но займет чуть больше времени.
LEARNING_RATE = 0.0005

# Количество эпох. 50–100 — хороший старт для RNN, 
# но может потребоваться больше, если данных очень много.
NUM_EPOCHS = 50

# Размер батча. 64 — стандартное значение. Можно менять в зависимости от объёма памяти и данных.
BATCH_SIZE = 64

# Длина входной последовательности (количество временных шагов).
# 50–60 для часовых данных обычно достаточно, но можно увеличить до 100–200,
# если модель не переобучается и есть запас по производительности.
SEQ_LEN = 60
